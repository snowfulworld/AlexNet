import os
import csv
import time
from util import read_from_csv,process_video_data,load_data,init_weight,plot_metrics
import torch
from model import AlexNet
from torch import nn
from datetime import datetime
import pandas as pd
import onnx

import argparse

def parse_args():
    parser = argparse.ArgumentParser(description="Sign Language Recognition Training")

    parser.add_argument('--frames_len', type=int, default=16, help='è§†é¢‘å †å å¸§æ•°')
    parser.add_argument('--batch_size', type=int, default=16, help='æ¯æ‰¹æ ·æœ¬æ•°')
    parser.add_argument('--epochs', type=int, default=300, help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=0.0001, help='å­¦ä¹ ç‡')

    return parser.parse_args()


def main():
    root="./result"
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    path=os.path.join(root,timestamp)
    os.makedirs(path, exist_ok=True)
    profile_path='./save' 
    model_dir="models"
    model_path=os.path.join(path,model_dir)
    log_dir="logs"
    log_path=os.path.join(path,log_dir)
    os.makedirs(model_path, exist_ok=True)
    os.makedirs(log_path, exist_ok=True)
    best_model_path = os.path.join(model_path,'AlexNet.pt')
    best_onnx_path=os.path.join(model_path,'AlexNet.onnx')
    # é»˜è®¤å‚æ•°è®¾ç½®
    args = parse_args()

    frames_len = args.frames_len
    batch_size = args.batch_size
    epochs = args.epochs
    learning_rate = args.lr
    #è¯»å–æ•°æ®
    labels_file=os.path.join(profile_path,'labels.txt')
    with open(labels_file, 'r', encoding='utf-8') as f:
        labels = f.readlines()
    labels = [label.strip() for label in labels]
    
    # è¯»å– train.csv å’Œ test.csv æ–‡ä»¶
    train_file=os.path.join(profile_path,'train.csv')
    test_file=os.path.join(profile_path,'test.csv')
    train_data_path, train_labels = read_from_csv(train_file)
    test_data_path, test_labels = read_from_csv(test_file)
    #å°†è§†é¢‘å¸§è¿›è¡Œå †å 
    train_data = process_video_data(train_data_path, frames_len=frames_len)
    test_data = process_video_data(test_data_path, frames_len=frames_len)
    #å°†æ ‡ç­¾å˜æˆæ•°å­—ç±»å‹
    train_labels = [labels.index(item) for item in train_labels if item in labels]
    test_labels = [labels.index(item) for item in test_labels if item in labels]
    
    train_iter=load_data(train_data,train_labels,batch_size)
    test_iter=load_data(test_data,test_labels,batch_size)
    for x,y in train_iter:
        print(x.shape)
        break
    
    
    # å®šä¹‰è®¾å¤‡
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("å½“å‰è®¾å¤‡ä¸º"+str(device))
    #æ¨¡å‹
    model=AlexNet(input_frames=frames_len,num_classes=len(labels)).to(device)
    model.apply(init_weight)
    #æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    loss_fn=nn.CrossEntropyLoss()
    optimizer=torch.optim.SGD(model.parameters(),lr=learning_rate)#0.001ä¼šå¯¼è‡´lossä¸ºnan
    # åˆå§‹åŒ–æœ€å°æµ‹è¯•æŸå¤±
    best_test_loss = float('inf')
    #è®­ç»ƒ
    train_len=len(train_iter.dataset)
    test_len = len(test_iter.dataset)
    print(test_len)
    all_train_acc, all_train_loss = [], []
    all_test_acc, all_test_loss = [], []

    best_test_loss = float('inf')
    best_epoch = 0
    shape = None

    start_time = time.time()
    for epoch in range(epochs):
        model.train()
        epoch_loss = 0
        epoch_acc = 0

        for x, y in train_iter:
            x, y = x.to(device), y.to(device)
            hat_y = model(x)
            loss = loss_fn(hat_y, y)
            epoch_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            epoch_acc += (hat_y.argmax(1) == y).sum().item()

        train_acc = epoch_acc / train_len
        all_train_acc.append(train_acc)
        all_train_loss.append(epoch_loss)

        # === æµ‹è¯• ===
        model.eval()
        test_acc = 0
        test_loss = 0
        with torch.no_grad():
            for x, y in test_iter:
                x, y = x.to(device), y.to(device)
                shape = x.shape
                hat_y = model(x)
                test_loss += loss_fn(hat_y, y).item()
                test_acc += (hat_y.argmax(1) == y).sum().item()

        test_acc /= test_len
        all_test_acc.append(test_acc)
        all_test_loss.append(test_loss)

        print(f"[{epoch+1}/{epochs}] âœ… Test Acc: {test_acc:.4f} | Loss: {test_loss:.4f}")

        # === ä¿å­˜æœ€ä¼˜æ¨¡å‹ ===
        if test_loss < best_test_loss:
            best_test_loss = test_loss
            best_epoch = epoch + 1
            torch.save(model,best_model_path)
            dummy_input = torch.randn(shape).to(device)
            torch.onnx.export(model, dummy_input, best_onnx_path, opset_version=11)
            print(f"ğŸš€ Best model saved at epoch {best_epoch} with test loss {best_test_loss:.4f}")

        # === æ¯è½®ä¿å­˜å›¾ï¼ˆè¦†ç›–ï¼‰ ===
        plot_metrics(
            all_train_loss, all_test_loss,
            all_train_acc, all_test_acc,
            save_path=os.path.join(log_path, "current.png"),
            annotate_last=False,
            epoch=epoch+1
        )
    end_time = time.time()
    total_time = end_time - start_time

    # === ä¿å­˜ CSV ===
    df = pd.DataFrame({
        'epoch': list(range(1, epochs+1)),
        'train_acc': all_train_acc,
        'train_loss': all_train_loss,
        'test_acc': all_test_acc,
        'test_loss': all_test_loss
    })
    df.to_csv(os.path.join(log_path, "training_log.csv"), index=False)

    # === å†™å…¥ TXT æ€»ç»“ ===
    with open(os.path.join(log_path, "results.txt"), "w") as f:
        f.write("è®­ç»ƒç»“æœæ€»ç»“\n")
        f.write("====================\n")
        # ğŸ”§ å‚æ•°è®°å½•éƒ¨åˆ†
        f.write(f"å‚æ•°è®¾ç½®ï¼š\n")
        f.write(f"  - å¸§æ•°ï¼ˆframes_lenï¼‰: {frames_len}\n")
        f.write(f"  - æ‰¹å¤§å°ï¼ˆbatch_sizeï¼‰: {batch_size}\n")
        f.write(f"  - å­¦ä¹ ç‡ï¼ˆlearning_rateï¼‰: {learning_rate}\n")
        f.write(f"  - æ€»è®­ç»ƒè½®æ•°ï¼ˆepochsï¼‰: {epochs}\n\n")

        # âœ… æœ€ç»ˆè®­ç»ƒç»“æœ
        f.write(f"æœ€åä¸€è½®è®­ç»ƒå‡†ç¡®ç‡ï¼ˆTrain Accï¼‰: {all_train_acc[-1]:.4f}\n")
        f.write(f"æœ€åä¸€è½®è®­ç»ƒæŸå¤±ï¼ˆTrain Lossï¼‰: {all_train_loss[-1]:.4f}\n")
        f.write(f"æœ€åä¸€è½®æµ‹è¯•å‡†ç¡®ç‡ï¼ˆTest Accï¼‰: {all_test_acc[-1]:.4f}\n")
        f.write(f"æœ€åä¸€è½®æµ‹è¯•æŸå¤±ï¼ˆTest Lossï¼‰: {all_test_loss[-1]:.4f}\n\n")

        # âœ… æœ€ä¼˜ç»“æœ
        f.write(f"æœ€ä¼˜æ¨¡å‹å‡ºç°åœ¨ç¬¬ {best_epoch} è½®\n")
        f.write(f"æœ€ä¼˜æµ‹è¯•æŸå¤±ï¼ˆBest Test Lossï¼‰: {best_test_loss:.4f}\n")
        f.write(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {total_time:.2f} ç§’\n")
        f.write("====================\n")

    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼ç»“æœä¿å­˜äºï¼š{log_path}")


if __name__ == "__main__":
    main()