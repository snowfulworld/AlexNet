# AlexNet
本项目意在便于初学者使用AlexNet模型进行视频数据的训练和推理，暂时实现比较简陋，主要采用的方法是将视频帧进行堆叠，输入是（224x224）大小被堆叠的灰色图像（有其他需求可以在util.py文件中进行修改），损失函数和优化器选用最基础的交叉熵和SGD，运行主要分为三步实现。

## 训练集和测试集的切分
split_datasets实现，主要目的是将自己的数据进行训练集和测试集的划分，由于考虑不全面，需要使用者根据自己的数据集进行编写，笔者的数据集是存放在一个文件夹下的多个mp4视频，标签在每个视频名中进行提取。

使用者只需要根据自己的数据集情况，实现在目录文件夹下创建一个save文件夹，保存3个文件。

一个是labels.txt文件，里面每行为该数据集的一个标签名，数据集有几个标签就有几行。

二是train.csv，里面有两列数据，第一列为path，记录被划分为训练集的视频的路径，不熟悉相对路径的可以写绝对路径，熟悉相对路径的写视频相对train.py的路径。第二列为label，记录每个视频的标签名。

三是test.csv，内容同train.csv类似。

## 训练
train实现，主要需要传入的参数有四个，可选择在代码中传入或者通过命令行使用--frames_len这种命令进行传入。一个参数是frames_len，为堆叠的图像数，从第一张开始取，如果多了就扔掉后面的帧，如果少了就会出现警告，跳过这个视频（后续或许会改进）。另外三个参数是batch_size,epochs和lr。

输出为在目录文件夹下出现一个result文件夹，下面创建一个以运行时间命名的文件夹，内部有两个文件夹，分别是models和logs，models存有当次运行的模型的最好模型pt文件和onnx文件。logs存有acc和loss图片，results结果文件，记录参数和最终结果，training_log每轮训练结果，便于后续进行分析。

## 推理
detect实现，主要传入两个参数，一个是frames_len，堆叠帧数，二是训练的记录文件夹，那个运行时间的文件夹名(必须传入)。

输出为在训练文件夹下出现一个inference_results文件，记录推理结果。

注意，这部分代码需要修改提取真实标签部分的代码，根据自己数据集进行提取，如果不需要可以直接删除。

# 结束
笔者技术有限，暂时只能写出这种代码，后续会不断改进，并且出更多模型。
有问题联系笔者QQ：3441613160

